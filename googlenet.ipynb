{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab719679",
   "metadata": {},
   "source": [
    "Paper link: https://arxiv.org/pdf/1409.4842\n",
    "\n",
    "Problem: Can we make networks more sparse while still being expressive and learnable? Fully connected layers are expensive and prone to overfitting.\n",
    "\n",
    "Sparse connections: Each neuron only connects to a small subset of neurons in the previous layer\n",
    "\n",
    "If two neurons are frequently active together, they are likely:\n",
    "- Responding to the same underlying cause\n",
    "- Inputs to the same higher-level feature\n",
    "\n",
    "1. Compute correlations between neurons in layer L\n",
    "2. Cluster neurons based on correlation\n",
    "3. Connect each neuron in layer L+1 to a cluster of neurons in layer L.\n",
    "\n",
    "This creates a sparse connectivity pattern that reflects the data distribution.\n",
    "Shared dependencies induce correlations between neurons.\n",
    "\n",
    "A lot of clusters can be concentrated in a small region, can be convered by 1x1 conv in the L + 1 layer.\n",
    "\n",
    "However, one can also expect that there will be a smaller number of more\n",
    "spatially spread out clusters that can be covered by convolutions over larger patches, and there\n",
    "will be a decreasing number of patches over larger and larger regions\n",
    "\n",
    "The reason why we use larger kernels as we move down is because we want larger receptive fields \n",
    "and reduced need for precise localization. As features become more abstract, we want each neuron to \n",
    "cover a larger area. (The ratio of 3×3 and 5×5 convolutions should increase as we move to higher layers.)\n",
    "\n",
    "Insert 1x1 conv layers to reduce the channel dimension. This preserves expressive power, dramatically reduces the number of parameters.\n",
    "\n",
    "- All the convolutions, including those inside the Inception modules, use rectified linear activation.\n",
    "\n",
    "“the strong performance of relatively shallower networks … suggests that the features produced by the layers in the middle of the network should be very discriminative”\n",
    "\n",
    "- implies that mid-level features (edges → textures → parts) are already quite useful for classification.\n",
    "\n",
    "**Outputs of all branches inside an Inception module must be concatenated.**\n",
    "All must output tensors with the same spatial dimensions, so that they can be concatenated along the channel dimension. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36ac91fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "class Path1(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class Path2(nn.Module):\n",
    "    def __init__(self, in_channels, reduce_channel, out_channels): # 128 for out_channel\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, reduce_channel, kernel_size=1, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(reduce_channel, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "class Path3(nn.Module):\n",
    "    def __init__(self, in_channels, reduce_channel, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, reduce_channel, kernel_size=1, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(reduce_channel, out_channels, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x   \n",
    "\n",
    "class Path4(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, padding=1, stride=1),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x            \n",
    "\n",
    "class InceptionBranches(nn.Module):\n",
    "    def __init__(self, in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_pool):\n",
    "        super().__init__()\n",
    "        self.path1 = Path1(in_channels, out_1x1)\n",
    "        self.path2 = Path2(in_channels, red_3x3, out_3x3)\n",
    "        self.path3 = Path3(in_channels, red_5x5, out_5x5)\n",
    "        self.path4 = Path4(in_channels, out_pool)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        p1 = self.path1(x)\n",
    "        p2 = self.path2(x)\n",
    "        p3 = self.path3(x)\n",
    "        p4 = self.path4(x)\n",
    "\n",
    "        return torch.cat([p1, p2, p3, p4], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45902908",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    def __init__(self, num_classes=100):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            # Stem: lighter initial layers for small images\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),  # Keep 32x32\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Inception 3a, 3b (reduced channels)\n",
    "            InceptionBranches(in_channels=64, out_1x1=32, red_3x3=48, out_3x3=64, red_5x5=8, out_5x5=16, out_pool=16),  # 128 out\n",
    "            InceptionBranches(in_channels=128, out_1x1=64, red_3x3=64, out_3x3=96, red_5x5=16, out_5x5=32, out_pool=32),  # 224 out\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),  # 16x16\n",
    "\n",
    "            # Inception 4a, 4b (fewer modules)\n",
    "            InceptionBranches(in_channels=224, out_1x1=96, red_3x3=64, out_3x3=128, red_5x5=16, out_5x5=32, out_pool=32),  # 288 out\n",
    "            InceptionBranches(in_channels=288, out_1x1=128, red_3x3=96, out_3x3=160, red_5x5=24, out_5x5=48, out_pool=48),  # 384 out\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),  # 8x8\n",
    "\n",
    "            # Inception 5a (final module)\n",
    "            InceptionBranches(in_channels=384, out_1x1=160, red_3x3=128, out_3x3=192, red_5x5=32, out_5x5=64, out_pool=64),  # 480 out\n",
    "        )\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc = nn.Linear(480, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ba092d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU Memory: 15.8 GB\n",
      "Starting Epoch 1\n",
      "Batch 0/44, Loss: 4.6045\n",
      "Epoch 1 finished\n",
      "Training - Loss: 4.5589\n",
      "Starting Epoch 2\n",
      "Batch 0/44, Loss: 4.4399\n",
      "Epoch 2 finished\n",
      "Training - Loss: 4.3840\n",
      "Epoch 2 finished\n",
      "average training loss is 4.3840\n",
      "Epoch 2 finished\n",
      "Training - Loss: 4.3840\n",
      "Validation - Loss: 4.3235\n",
      "Starting Epoch 3\n",
      "Batch 0/44, Loss: 4.3180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d976ff89f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d976ff89f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d976ff89f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d976ff89f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 finished\n",
      "Training - Loss: 4.2739\n",
      "Starting Epoch 4\n",
      "Batch 0/44, Loss: 4.1906\n",
      "Epoch 4 finished\n",
      "Training - Loss: 4.1512\n",
      "Epoch 4 finished\n",
      "average training loss is 4.1512\n",
      "Epoch 4 finished\n",
      "Training - Loss: 4.1512\n",
      "Validation - Loss: 4.0511\n",
      "Starting Epoch 5\n",
      "Batch 0/44, Loss: 4.0453\n",
      "Epoch 5 finished\n",
      "Training - Loss: 4.0740\n",
      "Starting Epoch 6\n",
      "Batch 0/44, Loss: 3.9457\n",
      "Epoch 6 finished\n",
      "Training - Loss: 3.9947\n",
      "Epoch 6 finished\n",
      "average training loss is 3.9947\n",
      "Epoch 6 finished\n",
      "Training - Loss: 3.9947\n",
      "Validation - Loss: 3.8473\n",
      "Starting Epoch 7\n",
      "Batch 0/44, Loss: 3.9125\n",
      "Epoch 7 finished\n",
      "Training - Loss: 3.8956\n",
      "Starting Epoch 8\n",
      "Batch 0/44, Loss: 3.8057\n",
      "Epoch 8 finished\n",
      "Training - Loss: 3.8273\n",
      "Epoch 8 finished\n",
      "average training loss is 3.8273\n",
      "Epoch 8 finished\n",
      "Training - Loss: 3.8273\n",
      "Validation - Loss: 3.9594\n",
      "Starting Epoch 9\n",
      "Batch 0/44, Loss: 4.0689\n",
      "Epoch 9 finished\n",
      "Training - Loss: 3.8178\n",
      "Starting Epoch 10\n",
      "Batch 0/44, Loss: 3.6722\n",
      "Epoch 10 finished\n",
      "Training - Loss: 3.6678\n",
      "Epoch 10 finished\n",
      "average training loss is 3.6678\n",
      "Epoch 10 finished\n",
      "Training - Loss: 3.6678\n",
      "Validation - Loss: 3.5890\n",
      "Starting Epoch 11\n",
      "Batch 0/44, Loss: 3.7663\n",
      "Epoch 11 finished\n",
      "Training - Loss: 3.6336\n",
      "Starting Epoch 12\n",
      "Batch 0/44, Loss: 3.5000\n",
      "Epoch 12 finished\n",
      "Training - Loss: 3.5286\n",
      "Epoch 12 finished\n",
      "average training loss is 3.5286\n",
      "Epoch 12 finished\n",
      "Training - Loss: 3.5286\n",
      "Validation - Loss: 3.3036\n",
      "Starting Epoch 13\n",
      "Batch 0/44, Loss: 3.4496\n",
      "Epoch 13 finished\n",
      "Training - Loss: 3.4194\n",
      "Starting Epoch 14\n",
      "Batch 0/44, Loss: 3.3644\n",
      "Epoch 14 finished\n",
      "Training - Loss: 3.3419\n",
      "Epoch 14 finished\n",
      "average training loss is 3.3419\n",
      "Epoch 14 finished\n",
      "Training - Loss: 3.3419\n",
      "Validation - Loss: 3.2373\n",
      "Starting Epoch 15\n",
      "Batch 0/44, Loss: 3.2578\n",
      "Epoch 15 finished\n",
      "Training - Loss: 3.2589\n",
      "Starting Epoch 16\n",
      "Batch 0/44, Loss: 3.2528\n",
      "Epoch 16 finished\n",
      "Training - Loss: 3.1843\n",
      "Epoch 16 finished\n",
      "average training loss is 3.1843\n",
      "Epoch 16 finished\n",
      "Training - Loss: 3.1843\n",
      "Validation - Loss: 2.9666\n",
      "Starting Epoch 17\n",
      "Batch 0/44, Loss: 3.0392\n",
      "Epoch 17 finished\n",
      "Training - Loss: 3.1217\n",
      "Starting Epoch 18\n",
      "Batch 0/44, Loss: 3.0105\n",
      "Epoch 18 finished\n",
      "Training - Loss: 3.0305\n",
      "Epoch 18 finished\n",
      "average training loss is 3.0305\n",
      "Epoch 18 finished\n",
      "Training - Loss: 3.0305\n",
      "Validation - Loss: 2.7839\n",
      "Starting Epoch 19\n",
      "Batch 0/44, Loss: 2.9622\n",
      "Epoch 19 finished\n",
      "Training - Loss: 2.9403\n",
      "Starting Epoch 20\n",
      "Batch 0/44, Loss: 2.8423\n",
      "Epoch 20 finished\n",
      "Training - Loss: 2.8845\n",
      "Epoch 20 finished\n",
      "average training loss is 2.8845\n",
      "Epoch 20 finished\n",
      "Training - Loss: 2.8845\n",
      "Validation - Loss: 2.7763\n",
      "Starting Epoch 21\n",
      "Batch 0/44, Loss: 2.8572\n",
      "Epoch 21 finished\n",
      "Training - Loss: 2.8312\n",
      "Starting Epoch 22\n",
      "Batch 0/44, Loss: 2.8278\n",
      "Epoch 22 finished\n",
      "Training - Loss: 2.7853\n",
      "Epoch 22 finished\n",
      "average training loss is 2.7853\n",
      "Epoch 22 finished\n",
      "Training - Loss: 2.7853\n",
      "Validation - Loss: 2.6159\n",
      "Starting Epoch 23\n",
      "Batch 0/44, Loss: 2.6864\n",
      "Epoch 23 finished\n",
      "Training - Loss: 2.7421\n",
      "Starting Epoch 24\n",
      "Batch 0/44, Loss: 2.6616\n",
      "Epoch 24 finished\n",
      "Training - Loss: 2.6920\n",
      "Epoch 24 finished\n",
      "average training loss is 2.6920\n",
      "Epoch 24 finished\n",
      "Training - Loss: 2.6920\n",
      "Validation - Loss: 2.5249\n",
      "Starting Epoch 25\n",
      "Batch 0/44, Loss: 2.6478\n",
      "Epoch 25 finished\n",
      "Training - Loss: 2.6461\n",
      "Starting Epoch 26\n",
      "Batch 0/44, Loss: 2.6179\n",
      "Epoch 26 finished\n",
      "Training - Loss: 2.6057\n",
      "Epoch 26 finished\n",
      "average training loss is 2.6057\n",
      "Epoch 26 finished\n",
      "Training - Loss: 2.6057\n",
      "Validation - Loss: 2.4537\n",
      "Starting Epoch 27\n",
      "Batch 0/44, Loss: 2.5415\n",
      "Epoch 27 finished\n",
      "Training - Loss: 2.5710\n",
      "Starting Epoch 28\n",
      "Batch 0/44, Loss: 2.5337\n",
      "Epoch 28 finished\n",
      "Training - Loss: 2.5327\n",
      "Epoch 28 finished\n",
      "average training loss is 2.5327\n",
      "Epoch 28 finished\n",
      "Training - Loss: 2.5327\n",
      "Validation - Loss: 2.4221\n",
      "Starting Epoch 29\n",
      "Batch 0/44, Loss: 2.5605\n",
      "Epoch 29 finished\n",
      "Training - Loss: 2.5004\n",
      "Starting Epoch 30\n",
      "Batch 0/44, Loss: 2.4263\n",
      "Epoch 30 finished\n",
      "Training - Loss: 2.4735\n",
      "Epoch 30 finished\n",
      "average training loss is 2.4735\n",
      "Epoch 30 finished\n",
      "Training - Loss: 2.4735\n",
      "Validation - Loss: 2.3615\n",
      "Starting Epoch 31\n",
      "Batch 0/44, Loss: 2.4761\n",
      "Epoch 31 finished\n",
      "Training - Loss: 2.4333\n",
      "Starting Epoch 32\n",
      "Batch 0/44, Loss: 2.3964\n",
      "Epoch 32 finished\n",
      "Training - Loss: 2.4066\n",
      "Epoch 32 finished\n",
      "average training loss is 2.4066\n",
      "Epoch 32 finished\n",
      "Training - Loss: 2.4066\n",
      "Validation - Loss: 2.3302\n",
      "Starting Epoch 33\n",
      "Batch 0/44, Loss: 2.3256\n",
      "Epoch 33 finished\n",
      "Training - Loss: 2.3820\n",
      "Starting Epoch 34\n",
      "Batch 0/44, Loss: 2.4021\n",
      "Epoch 34 finished\n",
      "Training - Loss: 2.3629\n",
      "Epoch 34 finished\n",
      "average training loss is 2.3629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d976ff89f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d976ff89f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 finished\n",
      "Training - Loss: 2.3629\n",
      "Validation - Loss: 2.2965\n",
      "Starting Epoch 35\n",
      "Batch 0/44, Loss: 2.3481\n",
      "Epoch 35 finished\n",
      "Training - Loss: 2.3509\n",
      "Starting Epoch 36\n",
      "Batch 0/44, Loss: 2.3651\n",
      "Epoch 36 finished\n",
      "Training - Loss: 2.3342\n",
      "Epoch 36 finished\n",
      "average training loss is 2.3342\n",
      "Epoch 36 finished\n",
      "Training - Loss: 2.3342\n",
      "Validation - Loss: 2.2859\n",
      "Starting Epoch 37\n",
      "Batch 0/44, Loss: 2.3193\n",
      "Epoch 37 finished\n",
      "Training - Loss: 2.3220\n",
      "Starting Epoch 38\n",
      "Batch 0/44, Loss: 2.3066\n",
      "Epoch 38 finished\n",
      "Training - Loss: 2.3118\n",
      "Epoch 38 finished\n",
      "average training loss is 2.3118\n",
      "Epoch 38 finished\n",
      "Training - Loss: 2.3118\n",
      "Validation - Loss: 2.2726\n",
      "Starting Epoch 39\n",
      "Batch 0/44, Loss: 2.3092\n",
      "Epoch 39 finished\n",
      "Training - Loss: 2.3118\n",
      "Starting Epoch 40\n",
      "Batch 0/44, Loss: 2.3418\n",
      "Epoch 40 finished\n",
      "Training - Loss: 2.3025\n",
      "Epoch 40 finished\n",
      "average training loss is 2.3025\n",
      "Epoch 40 finished\n",
      "Training - Loss: 2.3025\n",
      "Validation - Loss: 2.2714\n"
     ]
    }
   ],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Mild to avoid over-distortion\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5071, 0.4865, 0.4409], std=[0.2673, 0.2564, 0.2761]),\n",
    "    transforms.RandomErasing(p=0.25)  # Apply after normalization for consistency\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # Moved ToTensor before Normalize (good practice)\n",
    "    transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])\n",
    "])\n",
    "\n",
    "# Load raw datasets\n",
    "cifar_train_raw = datasets.CIFAR100(root=\"./data\", train=True, download=True, transform=None)\n",
    "\n",
    "train_size = int(0.9 * len(cifar_train_raw))  # 48,000\n",
    "\n",
    "train_indices = list(range(0, train_size))\n",
    "val_indices = list(range(train_size, len(cifar_train_raw)))\n",
    "\n",
    "# Create datasets with appropriate transforms\n",
    "cifar_train = Subset(\n",
    "    datasets.CIFAR100(root=\"./data\", train=True, transform=train_transform),\n",
    "    train_indices\n",
    ")\n",
    "cifar_val = Subset(\n",
    "    datasets.CIFAR100(root=\"./data\", train=True, transform=test_transform),\n",
    "    val_indices\n",
    ")\n",
    "# Use original test set (10,000 samples) - close to 10% of 60,000\n",
    "cifar_test = datasets.CIFAR100(root=\"./data\", train=False, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    cifar_train,\n",
    "    batch_size=1024,  # Changed from 1024\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=6\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    cifar_val,  # Use directly\n",
    "    batch_size=1024,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=6\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    cifar_test,\n",
    "    batch_size=1024,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=6\n",
    ")\n",
    "\n",
    "num_classes = 100\n",
    "\n",
    "model = Inception().to(device)\n",
    "\n",
    "num_epochs = 40\n",
    "loss_function = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "base_lr = 4e-3\n",
    "\n",
    "batch_scale = 1024 / 256  # 4x larger batches\n",
    "scaled_lr = base_lr * batch_scale**0.5  # Square root scaling\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=3e-3,  # Changed from 1e-3\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=1e-2,  # Changed from 3e-3\n",
    "    epochs=num_epochs,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    pct_start=0.3,\n",
    "    anneal_strategy='cos',\n",
    "    div_factor=25.0,\n",
    "    final_div_factor=1000.0\n",
    ")\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Starting Epoch {epoch+1}')\n",
    "    model.train()\n",
    "\n",
    "    current_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, targets = data\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)  # Changed from 1.0\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        scheduler.step()\n",
    "\n",
    "        current_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print(f'Batch {i}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "    avg_train_loss = current_loss / num_batches\n",
    "    print(f'Epoch {epoch+1} finished')\n",
    "    print(f'Training - Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_batches = 0\n",
    "\n",
    "        print(f'Epoch {epoch+1} finished')\n",
    "        print(f'average training loss is {avg_train_loss:.4f}')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_data in val_loader:\n",
    "                val_inputs, val_targets = val_data\n",
    "                val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)  # Convert inputs to FP16\n",
    "\n",
    "                val_outputs = model(val_inputs)\n",
    "                val_batch_loss = loss_function(val_outputs, val_targets)\n",
    "\n",
    "                val_loss += val_batch_loss.item()\n",
    "                val_batches += 1\n",
    "\n",
    "\n",
    "        avg_val_loss = val_loss / val_batches\n",
    "\n",
    "        print(f'Epoch {epoch+1} finished')\n",
    "        print(f'Training - Loss: {avg_train_loss:.4f}')\n",
    "        print(f'Validation - Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1355da75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running standard evaluation ===\n",
      "Starting evaluation...\n",
      "Accuracy of the network on the test images: 56.68%\n",
      "Standard Test Accuracy: 56.6800 (5668.00%)\n"
     ]
    }
   ],
   "source": [
    "def evaluate_test_set(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    print(\"Starting evaluation...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Use autocast for consistency if you trained with it\n",
    "            outputs = model(images)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy of the network on the test images: {accuracy:.2f}%')\n",
    "    return accuracy\n",
    "\n",
    "print(\"\\n=== Running standard evaluation ===\")\n",
    "standard_accuracy = evaluate_test_set(model)   \n",
    "print(f'Standard Test Accuracy: {standard_accuracy:.4f} ({standard_accuracy*100:.2f}%)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
